{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT'S WHY WE HAVE BEEN SO SUCCESSFUL IN PASSING THIS LEGISLATION NUMEROUS TIMES OUT OF THE WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TO"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER TAX RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER TAX RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLOR"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST OF GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. ... LEGISLATION WAS APPROVED LAST YEAR BY THE WAYS AND MEANS COMMITTEE 38-0 BECAUSE FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMM"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nCALIFORNIA IS RECOGNIZED. I YIELD MYSELF\nSUCH TIME AS I MAY CONSUME. JARNGD. I RISE IN STRONG SUPPORT OF THIS LEGISLATION AND I THANK CHAIRMAN SMITH OF THE WAYS AND MEANS COMMITTEE FOR ALL OF THE GOOD WORK HE HAS DONE TO ENSURE WE ARE ABLE TO HELP OUR CONSTITUENTS WHO ARE SUFFERING AS A RESULT OF NATURAL DISASTERS AND COLLEAGUE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTIT"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "THST:\nTHE : WITHOUT\nOBJECTION\nTHE GENTLEMAN IS RECOGNIZED THANK YOU, MR. SPEAKER, I RISE IN SUPPORT OF H.R. 5863, THE FEDERAL DISASTER TAX RELIEF ACT. INTRODUCED BY MY WAYS AND MEANS COLLEAGUE FROM BEL STEUBE. THIS LEGISLATION WAS APPROVED LAST YEAR BY THE WAYS AND MEANS COMMITTEE 38-0 BECAUSE FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "UE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT TO BE A BIPARTISAN VICTORY, THEY HAVE BEEN SITTING ON THE TAX BILL FOR FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNIT"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST OF GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nCALIFORN"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE FIRES. AS PART OF ITS SUBSEQUENT BANKRUPTCY PROCEEDINGS, THE UTILITY ESTABLISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SA"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "OMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR. STEUBE, ONE OF OUR COL LEAGUES ON THE COM MITTEE. I W ISH SUCH AN UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. ... WE ARE ABLE TO HELP"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR. STEUBE, ONE OF OUR COL LEAGUES ON THE COM MITTEE. I W ISH SUCH AN UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nMISSOURI IS RECOGNIZED. I WANT TO THANK CONGRESSMAN THOMPSON FOR HIS ADVOCACY ON HIS LEGISLATION AND MOVING IT THROUGH THE COMMITTEE IN A VERY BIPARTISAN EFFORT. I YIELD SUCH TIME AS HE MAY CONSUME"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE FIRES. AS PART OF ITS SUBSEQUENT BANKRUPTCY PROCEEDINGS, THE UTILITY ESTABLISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT'S WHY WE HAVE BEEN SO SUCCESSFUL IN PASSING THIS LEGISLATION NUMEROUS TIMES OUT OF THE WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT TO BE A BIPARTISAN VICTORY, THEY HAVE BEEN SITTING ON THE TAX BILL FOR FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO VICTIMS OF NATURAL DISASTERS. SINCE 2021, 3 1-R DISASTERS HAVE BEEN DECLARED WITHOUT CONGRESS TAKING ACTION. WILDFIRES ACROSS THE WESTERN UNITED STATES AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "UES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nMISSOURI IS RECOGNIZED. I WANT TO THANK CONGRESSMAN THOMPSON FOR HIS ADVOCACY ON HIS LEGISLATION AND MOVING IT THROUGH THE COMMITTEE IN A VERY BIPARTISAN EFFORT. I YIELD SUCH TIME AS HE MAY CONSUME TO THE AUTHOR OF THIS LEGISLATION, THE GENTLEMAN FROM FLORIDA, MR. STEUBE. ... TIME AS HE MAY CONSUME TO THE AUTHOR OF THIS LEGISLATION, THE GENTLEMAN FROM FLORIDA, MR. STEUBE. THE\nGENTLEMAN IS RECOGNIZEDST I STAND IN SUPPORT OF H.R. 5863. AND HISTORIC ACT LAST WEEK THE MAJORITY OF THE HOUSE OF REPRESENTATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE K"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO V"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. ... WE ARE ABLE TO HELP OUR CONSTITUENTS WHO ARE SUFFERING AS A RESULT OF NATURAL DISASTERS AND COLLEAGUE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. ... RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "IDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO VICTIMS OF NATURAL DISASTERS. SINCE 2021, 3 1-R DISASTERS HAVE BEEN DECLARED WITHOUT CONGRESS TAKING ACTION. WILDFIRES ACROSS THE WESTERN UNITED STATES AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A VARIETY OF DISASTERS, INCLUDING TORNADOES, FLOODING AND FIRES. THIS DOESN'T JUST IMPACT CALIFORNIA, IT CONGRESS MUST ACT TO PROVIDE THEM RELIEF. I'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA,"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A VARIETY OF DISASTERS, INCLUDING TORNADOES, FLOODING AND FIRES. THIS DOESN'T JUST IMPACT CALIFORNIA, IT CONGRESS MUST ACT TO PROVIDE THEM RELIEF. I'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "IEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA, AS WELL AS CONGRESSWOMAN JOE WILSON TOKUDA OF HAWAII FOR THEIR LEADERSHIP ON THIS EFFORT. I'D LIKE TO THANK CONGRESSMAN BILL JOHNSON WHO PLAYED AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. ... RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "S FIRSTHAND THE TRAGEDY OF WILDFIRES, HER CONSTITUENTS EX PERIENCED A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. ... A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. THE\nGENTLELADY FROM HAWAII IS\nRECOGNIZED FOR TO MINUTES. THANK YOU, MR. SPEAKER. I RISE IN STRONG SUPPORT OF H.R. 586 3-RBGS THE FEDERAL DISASTER TAX RELIEF ACT OF 2023. IT WILL KEEP SURVIVORS' HARD-EARNED MONEY IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "IEF ACT OF 2023. IT WILL KEEP SURVIVORS' HARD-EARNED MONEY IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD EVER BUDGET FOR. ACROSS OUR COUNTRY, THROUGH ALL DISASTERS, CURRENT, THOSE TO COME AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "E AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING WE CAN DO TO LIGHTEN THE TAX BURDENS AND THE FINANCIAL STRUGGLES THEY FACE WILL IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN."}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA, AS WELL AS CONGRESSWOMAN JOE WILSON TOKUDA OF HAWAII FOR THEIR LEADERSHIP ON THIS EFFORT. I'D LIKE TO THANK CONGRESSMAN BILL JOHNSON WHO PLAYED AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. THE\nGENTLEMAN FROM FLORIDA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. SPEAKER, I'D LIKE TO YIELD TWO MINUTES TO THE GENTLELADY 2ROM 2AWAII, MS. TOKUDA, WHO KNOWS FIRSTHAND THE TRAGEDY OF WILDFIRES, HER CONSTITUENTS EX PERIENCED A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. ... A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD EVER BUDGET FOR. ACROSS OUR COUNTRY, THROUGH ALL DISASTERS, CURRENT, THOSE TO COME AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. ... IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "IMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. THE\nGENTLELADY YIELDS BACK.\nTHE GENTLEMAN FROM CALIFORNIA\nRESERVES.\nAND THE GENTLEMAN FROM MISSOURI\nIS RECOGNIZED. YOU, MR. SPEAKER.\nI YIELD SUCH TIME AS HE MAY\nCONSUME TO THE GENTLEMAN FROM\nCALIFORNIA, MR. LAMALFA. THE\nGENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. THANK YOU, MR. SPEAKER. AND THANK YOU SO MUCH, CHAIRMAN SMITH, FOR HELPING US WITH OUR LEGISLATION ALL THIS TIME HERE AND I'M VERY GRATEFUL ALSO TO MR. STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIP"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "THIS TIME HERE AND I'M VERY GRATEFUL ALSO TO MR. STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , WIT H THE LOSSES WE'VE SUFFERED, ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING WE CAN DO TO LIGHTEN THE TAX BURDENS AND THE FINANCIAL STRUGGLES THEY FACE WILL IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. THE\nGENTLELADY YIELDS BACK.\nTHE GENTLEMAN FROM CALIFORNIA\nRESERVES.\nAND THE GENTLE"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "LY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR MORTGAGE, MAYBE IT'S ALREADY PAID OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING, DID THEIR NEIGHBOR GET OUT? DID THE ELDERLY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE ST"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS, WE WANT TO GET R ESULTS. IT'S BEEN A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RESOUNDINGLY. I HOPE SO. I ASK FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY P"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME BECAUSE OF A BAD INTERPRETATION HERE? THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "WAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING, DID THEIR NEIGHBOR GET OUT? DID THE ELDERLY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR M"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RESOUNDINGLY. I HOPE SO. I ASK FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. MR. SPEAKER, I\nHAVE NO FURTHER SPEAKERS AND"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , WIT H THE LOSSES WE'VE SUFFERED, ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS,"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS, WE WANT TO GET R ESULTS. IT'S BEEN A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING,"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. ... STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , W"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME BECAUSE OF A BAD INTERPRETATION HERE? THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RES"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR MORTGAGE, MAYBE IT'S ALREADY PAID OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK, C ALIFORNIA AND OVER A DOZEN O THER STATES HAVE BE EN DEVASTA TED BY DISA STE RS. THERE'S NOT A SINGL E COLLEAG UE IN THIS HO USE WHO SHOULD HAVE TO GO THROUGH A DISASTE R TO KNOW HO W BAD IT IS. THI S DE VASTA TES COMMUNITIES, IT DEVASTA TES PEOPLE'S LIVES, IT DISRUPT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMEND"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "PT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMITTEE AND EVERY MEMBER ON THIS -- IN THIS HOUSE SHOULD BE PROUD TO COME TO THE FLOOR AND VOTE TO SUPPORT THEIR FRIENDS, THEIR NEIGHBORS, THEIR CONSTITUENTS IN THESE VERY, VERY DARK TIMES. I YIELD BACK THE BALANCE OF MY TIME. ... TO BRING THIS BILL TO FRUI TIO N NOT ONCE, NOT TWICE, BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "LATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. MR. SPEAKER, I\nHAVE NO FURTHER SPEAKERS AND I'M\nPREPARED TO CLOSE. WE'RE PREPARED TO\nCLOSE. THE\nGENTLEMAN IS RECOGNIZED. THANK YOU, MR. SPEAKER. AGAIN, I'D LIKE TO THANK MR. STEUBE, MR. LAMALFA, CHAIRMAN SMITH AND ALL OF OUR COLLEAGUES ON WAYS AND MEANS WHO WORKED SO HARD TO BRING THIS BILL TO FRUI TIO N NOT ONCE, NOT TWICE, BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, K"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "PTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMITTEE AND EVERY MEMBER ON THIS -- IN THIS HOUSE SHOULD BE PROUD TO COME TO THE FLOOR AND VOTE TO SUPPORT THEIR FRIENDS, THEIR NEIGHBORS, THEIR CONSTITUENTS IN THESE VERY, VERY DARK TIMES. I YIELD BACK THE BALANCE OF MY TIME. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI IS\nRECOGNIZED. THANK YOU, MR. SPEAKER. MR. SPEAKER, I WOULD ONCE AGAIN JUST COMMEND THE GREAT WORK AND ADVOCACY THAT MR. STEUBE, MR. LA MALFA, MR. THOMPSON -- I CAN TELL YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "MR. SPEAKER, I WOULD ONCE AGAIN JUST COMMEND THE GREAT WORK AND ADVOCACY THAT MR. STEUBE, MR. LA MALFA, MR. THOMPSON -- I CAN TELL YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT, I URGE ALL MEMBERS TO SUPP REMARKS ARE ABOUT HALF AN HOUR. ... YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT, I URGE ALL MEMBERS TO SUPP REMARKS ARE ABOUT HALF AN HOUR."}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"input": "It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 173, in _process_document\n    continuation = await self._llm(\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\nTypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'\n", "source": "AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'", "details": {"doc_index": 0, "text": "FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK, C ALIFORNIA AND OVER A DOZEN O THER STATES HAVE BE EN DEVASTA TED BY DISA STE RS. THERE'S NOT A SINGL E COLLEAG UE IN THIS HO USE WHO SHOULD HAVE TO GO THROUGH A DISASTE R TO KNOW HO W BAD IT IS. THI S DE VASTA TES COMMUNITIES, IT DEVASTA TES PEOPLE'S LIVES, IT DISRUPT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMIT"}}
{"type": "error", "data": "Error executing verb \"cluster_graph\" in create_base_entity_graph: Columns must be same length as key", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 410, in _execute_verb\n    result = node.verb.func(**verb_args)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/verbs/graph/clustering/cluster_graph.py\", line 102, in cluster_graph\n    output_df[[level_to, to]] = pd.DataFrame(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\", line 4299, in __setitem__\n    self._setitem_array(key, value)\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\", line 4341, in _setitem_array\n    check_key_length(self.columns, key, value)\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/indexers/utils.py\", line 390, in check_key_length\n    raise ValueError(\"Columns must be same length as key\")\nValueError: Columns must be same length as key\n", "source": "Columns must be same length as key", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/run.py\", line 323, in run_pipeline\n    result = await workflow.run(context, callbacks)\n  File \"/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n  File \"/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 410, in _execute_verb\n    result = node.verb.func(**verb_args)\n  File \"/usr/local/lib/python3.10/site-packages/graphrag/index/verbs/graph/clustering/cluster_graph.py\", line 102, in cluster_graph\n    output_df[[level_to, to]] = pd.DataFrame(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\", line 4299, in __setitem__\n    self._setitem_array(key, value)\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\", line 4341, in _setitem_array\n    check_key_length(self.columns, key, value)\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/indexers/utils.py\", line 390, in check_key_length\n    raise ValueError(\"Columns must be same length as key\")\nValueError: Columns must be same length as key\n", "source": "Columns must be same length as key", "details": null}
