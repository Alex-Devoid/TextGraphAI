18:29:05,929 graphrag.config.read_dotenv INFO No .env file found at app
18:29:05,936 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 56",
        "type": "openai_chat",
        "model": "gpt-4o",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "app",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 5,
        "strategy": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
18:29:05,951 graphrag.index.create_pipeline_config INFO skipping workflows 
18:29:05,957 graphrag.index.run INFO Running pipeline
18:29:05,959 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at app/output/20240801-182905/artifacts
18:29:05,985 graphrag.index.input.load_input INFO loading input from root_dir=input
18:29:05,988 graphrag.index.input.load_input INFO using file storage for input
18:29:05,995 graphrag.index.storage.file_pipeline_storage INFO search app/input for files matching .*\.txt$
18:29:06,8 graphrag.index.input.text INFO found text files from input, found [('full_transcript.txt', {})]
18:29:06,36 graphrag.index.input.text INFO Found 1 files, loading 1
18:29:06,40 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
18:29:06,43 graphrag.index.run INFO Final # of rows loaded: 1
18:29:06,180 graphrag.index.run INFO Running workflow: create_base_text_units...
18:29:06,192 graphrag.index.run INFO dependencies for create_base_text_units: []
18:29:06,194 datashaper.workflow.workflow INFO executing verb orderby
18:29:06,198 datashaper.workflow.workflow INFO executing verb zip
18:29:06,200 datashaper.workflow.workflow INFO executing verb aggregate_override
18:29:06,205 datashaper.workflow.workflow INFO executing verb chunk
18:29:08,488 datashaper.workflow.workflow INFO executing verb select
18:29:08,501 datashaper.workflow.workflow INFO executing verb unroll
18:29:08,598 datashaper.workflow.workflow INFO executing verb rename
18:29:08,607 datashaper.workflow.workflow INFO executing verb genid
18:29:08,621 datashaper.workflow.workflow INFO executing verb unzip
18:29:08,638 datashaper.workflow.workflow INFO executing verb copy
18:29:08,641 datashaper.workflow.workflow INFO executing verb filter
18:29:08,696 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
18:29:08,927 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
18:29:08,928 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
18:29:08,931 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
18:29:08,959 datashaper.workflow.workflow INFO executing verb entity_extract
18:29:08,967 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
18:29:08,996 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
18:29:08,998 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
18:29:09,154 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,157 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,162 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT'S WHY WE HAVE BEEN SO SUCCESSFUL IN PASSING THIS LEGISLATION NUMEROUS TIMES OUT OF THE WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TO"}
18:29:09,165 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,167 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,172 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER TAX RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST"}
18:29:09,176 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,177 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,193 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER TAX RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLOR"}
18:29:09,195 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,198 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,207 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'ORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST OF GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. ... LEGISLATION WAS APPROVED LAST YEAR BY THE WAYS AND MEANS COMMITTEE 38-0 BECAUSE FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMM'}
18:29:09,211 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,213 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,219 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nCALIFORNIA IS RECOGNIZED. I YIELD MYSELF\nSUCH TIME AS I MAY CONSUME. JARNGD. I RISE IN STRONG SUPPORT OF THIS LEGISLATION AND I THANK CHAIRMAN SMITH OF THE WAYS AND MEANS COMMITTEE FOR ALL OF THE GOOD WORK HE HAS DONE TO ENSURE WE ARE ABLE TO HELP OUR CONSTITUENTS WHO ARE SUFFERING AS A RESULT OF NATURAL DISASTERS AND COLLEAGUE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTIT"}
18:29:09,221 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,222 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,229 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THST:\nTHE : WITHOUT\nOBJECTION\nTHE GENTLEMAN IS RECOGNIZED THANK YOU, MR. SPEAKER, I RISE IN SUPPORT OF H.R. 5863, THE FEDERAL DISASTER TAX RELIEF ACT. INTRODUCED BY MY WAYS AND MEANS COLLEAGUE FROM BEL STEUBE. THIS LEGISLATION WAS APPROVED LAST YEAR BY THE WAYS AND MEANS COMMITTEE 38-0 BECAUSE FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER"}
18:29:09,231 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,233 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,241 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "UE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT TO BE A BIPARTISAN VICTORY, THEY HAVE BEEN SITTING ON THE TAX BILL FOR FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNIT"}
18:29:09,269 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,271 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,278 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST OF GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nCALIFORN'}
18:29:09,280 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,282 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,296 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE FIRES. AS PART OF ITS SUBSEQUENT BANKRUPTCY PROCEEDINGS, THE UTILITY ESTABLISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SA'}
18:29:09,306 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,316 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,323 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS"}
18:29:09,343 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,345 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,352 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "OMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT"}
18:29:09,354 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,355 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,363 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR. STEUBE, ONE OF OUR COL LEAGUES ON THE COM MITTEE. I W ISH SUCH AN UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. ... WE ARE ABLE TO HELP"}
18:29:09,365 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,366 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,369 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR. STEUBE, ONE OF OUR COL LEAGUES ON THE COM MITTEE. I W ISH SUCH AN UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nMISSOURI IS RECOGNIZED. I WANT TO THANK CONGRESSMAN THOMPSON FOR HIS ADVOCACY ON HIS LEGISLATION AND MOVING IT THROUGH THE COMMITTEE IN A VERY BIPARTISAN EFFORT. I YIELD SUCH TIME AS HE MAY CONSUME"}
18:29:09,373 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,375 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,378 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE FIRES. AS PART OF ITS SUBSEQUENT BANKRUPTCY PROCEEDINGS, THE UTILITY ESTABLISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND"}
18:29:09,382 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,384 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,394 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT'S WHY WE HAVE BEEN SO SUCCESSFUL IN PASSING THIS LEGISLATION NUMEROUS TIMES OUT OF THE WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR"}
18:29:09,410 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,413 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,418 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'ED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT TO BE A BIPARTISAN VICTORY, THEY HAVE BEEN SITTING ON THE TAX BILL FOR FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE'}
18:29:09,421 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,422 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,431 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO VICTIMS OF NATURAL DISASTERS. SINCE 2021, 3 1-R DISASTERS HAVE BEEN DECLARED WITHOUT CONGRESS TAKING ACTION. WILDFIRES ACROSS THE WESTERN UNITED STATES AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A'}
18:29:09,436 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,437 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,443 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'UES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nMISSOURI IS RECOGNIZED. I WANT TO THANK CONGRESSMAN THOMPSON FOR HIS ADVOCACY ON HIS LEGISLATION AND MOVING IT THROUGH THE COMMITTEE IN A VERY BIPARTISAN EFFORT. I YIELD SUCH TIME AS HE MAY CONSUME TO THE AUTHOR OF THIS LEGISLATION, THE GENTLEMAN FROM FLORIDA, MR. STEUBE. ... TIME AS HE MAY CONSUME TO THE AUTHOR OF THIS LEGISLATION, THE GENTLEMAN FROM FLORIDA, MR. STEUBE. THE\nGENTLEMAN IS RECOGNIZEDST I STAND IN SUPPORT OF H.R. 5863. AND HISTORIC ACT LAST WEEK THE MAJORITY OF THE HOUSE OF REPRESENTATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE K'}
18:29:09,454 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,456 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,465 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'ATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO V'}
18:29:09,469 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,474 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,481 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. ... WE ARE ABLE TO HELP OUR CONSTITUENTS WHO ARE SUFFERING AS A RESULT OF NATURAL DISASTERS AND COLLEAGUE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT"}
18:29:09,508 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,516 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,528 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. ... RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP'}
18:29:09,533 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,539 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,549 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'IDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO VICTIMS OF NATURAL DISASTERS. SINCE 2021, 3 1-R DISASTERS HAVE BEEN DECLARED WITHOUT CONGRESS TAKING ACTION. WILDFIRES ACROSS THE WESTERN UNITED STATES AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN'}
18:29:09,551 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,551 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,556 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A VARIETY OF DISASTERS, INCLUDING TORNADOES, FLOODING AND FIRES. THIS DOESN'T JUST IMPACT CALIFORNIA, IT CONGRESS MUST ACT TO PROVIDE THEM RELIEF. I'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA,"}
18:29:09,563 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,565 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,574 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A VARIETY OF DISASTERS, INCLUDING TORNADOES, FLOODING AND FIRES. THIS DOESN'T JUST IMPACT CALIFORNIA, IT CONGRESS MUST ACT TO PROVIDE THEM RELIEF. I'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND"}
18:29:09,576 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,577 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,615 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA, AS WELL AS CONGRESSWOMAN JOE WILSON TOKUDA OF HAWAII FOR THEIR LEADERSHIP ON THIS EFFORT. I'D LIKE TO THANK CONGRESSMAN BILL JOHNSON WHO PLAYED AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. ... RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON"}
18:29:09,632 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,633 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,639 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "S FIRSTHAND THE TRAGEDY OF WILDFIRES, HER CONSTITUENTS EX PERIENCED A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. ... A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. THE\nGENTLELADY FROM HAWAII IS\nRECOGNIZED FOR TO MINUTES. THANK YOU, MR. SPEAKER. I RISE IN STRONG SUPPORT OF H.R. 586 3-RBGS THE FEDERAL DISASTER TAX RELIEF ACT OF 2023. IT WILL KEEP SURVIVORS' HARD-EARNED MONEY IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL"}
18:29:09,642 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,644 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,650 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IEF ACT OF 2023. IT WILL KEEP SURVIVORS' HARD-EARNED MONEY IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD EVER BUDGET FOR. ACROSS OUR COUNTRY, THROUGH ALL DISASTERS, CURRENT, THOSE TO COME AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION"}
18:29:09,652 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,653 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,658 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "E AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING WE CAN DO TO LIGHTEN THE TAX BURDENS AND THE FINANCIAL STRUGGLES THEY FACE WILL IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN."}
18:29:09,660 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,661 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,667 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA, AS WELL AS CONGRESSWOMAN JOE WILSON TOKUDA OF HAWAII FOR THEIR LEADERSHIP ON THIS EFFORT. I'D LIKE TO THANK CONGRESSMAN BILL JOHNSON WHO PLAYED AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS"}
18:29:09,668 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,670 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,676 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. THE\nGENTLEMAN FROM FLORIDA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. SPEAKER, I'D LIKE TO YIELD TWO MINUTES TO THE GENTLELADY 2ROM 2AWAII, MS. TOKUDA, WHO KNOWS FIRSTHAND THE TRAGEDY OF WILDFIRES, HER CONSTITUENTS EX PERIENCED A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. ... A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN"}
18:29:09,705 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,707 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,712 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD EVER BUDGET FOR. ACROSS OUR COUNTRY, THROUGH ALL DISASTERS, CURRENT, THOSE TO COME AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING"}
18:29:09,715 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,716 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,723 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. ... IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD"}
18:29:09,724 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,725 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,731 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. THE\nGENTLELADY YIELDS BACK.\nTHE GENTLEMAN FROM CALIFORNIA\nRESERVES.\nAND THE GENTLEMAN FROM MISSOURI\nIS RECOGNIZED. YOU, MR. SPEAKER.\nI YIELD SUCH TIME AS HE MAY\nCONSUME TO THE GENTLEMAN FROM\nCALIFORNIA, MR. LAMALFA. THE\nGENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. THANK YOU, MR. SPEAKER. AND THANK YOU SO MUCH, CHAIRMAN SMITH, FOR HELPING US WITH OUR LEGISLATION ALL THIS TIME HERE AND I'M VERY GRATEFUL ALSO TO MR. STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIP"}
18:29:09,732 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,733 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,737 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THIS TIME HERE AND I'M VERY GRATEFUL ALSO TO MR. STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , WIT H THE LOSSES WE'VE SUFFERED, ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE"}
18:29:09,751 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,754 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,767 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING WE CAN DO TO LIGHTEN THE TAX BURDENS AND THE FINANCIAL STRUGGLES THEY FACE WILL IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. THE\nGENTLELADY YIELDS BACK.\nTHE GENTLEMAN FROM CALIFORNIA\nRESERVES.\nAND THE GENTLE"}
18:29:09,771 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,774 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,808 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "LY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR MORTGAGE, MAYBE IT'S ALREADY PAID OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW"}
18:29:09,816 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,817 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,826 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING, DID THEIR NEIGHBOR GET OUT? DID THE ELDERLY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE ST"}
18:29:09,831 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,834 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,837 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS, WE WANT TO GET R ESULTS. IT'S BEEN A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE"}
18:29:09,859 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,862 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,865 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RESOUNDINGLY. I HOPE SO. I ASK FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY P"}
18:29:09,877 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,886 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:09,913 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME BECAUSE OF A BAD INTERPRETATION HERE? THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES"}
18:29:09,982 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:09,995 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,7 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "WAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING, DID THEIR NEIGHBOR GET OUT? DID THE ELDERLY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR M"}
18:29:10,22 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,31 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,44 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RESOUNDINGLY. I HOPE SO. I ASK FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. MR. SPEAKER, I\nHAVE NO FURTHER SPEAKERS AND"}
18:29:10,48 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,51 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,56 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , WIT H THE LOSSES WE'VE SUFFERED, ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS,"}
18:29:10,73 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,77 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,80 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS, WE WANT TO GET R ESULTS. IT'S BEEN A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING,"}
18:29:10,83 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,84 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,95 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. ... STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , W"}
18:29:10,101 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,103 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,113 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME BECAUSE OF A BAD INTERPRETATION HERE? THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RES"}
18:29:10,115 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,116 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,130 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR MORTGAGE, MAYBE IT'S ALREADY PAID OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME"}
18:29:10,148 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,152 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,165 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK, C ALIFORNIA AND OVER A DOZEN O THER STATES HAVE BE EN DEVASTA TED BY DISA STE RS. THERE'S NOT A SINGL E COLLEAG UE IN THIS HO USE WHO SHOULD HAVE TO GO THROUGH A DISASTE R TO KNOW HO W BAD IT IS. THI S DE VASTA TES COMMUNITIES, IT DEVASTA TES PEOPLE'S LIVES, IT DISRUPT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMEND"}
18:29:10,179 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,201 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,214 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "PT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMITTEE AND EVERY MEMBER ON THIS -- IN THIS HOUSE SHOULD BE PROUD TO COME TO THE FLOOR AND VOTE TO SUPPORT THEIR FRIENDS, THEIR NEIGHBORS, THEIR CONSTITUENTS IN THESE VERY, VERY DARK TIMES. I YIELD BACK THE BALANCE OF MY TIME. ... TO BRING THIS BILL TO FRUI TIO N NOT ONCE, NOT TWICE, BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK"}
18:29:10,218 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,220 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,454 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "LATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. MR. SPEAKER, I\nHAVE NO FURTHER SPEAKERS AND I'M\nPREPARED TO CLOSE. WE'RE PREPARED TO\nCLOSE. THE\nGENTLEMAN IS RECOGNIZED. THANK YOU, MR. SPEAKER. AGAIN, I'D LIKE TO THANK MR. STEUBE, MR. LAMALFA, CHAIRMAN SMITH AND ALL OF OUR COLLEAGUES ON WAYS AND MEANS WHO WORKED SO HARD TO BRING THIS BILL TO FRUI TIO N NOT ONCE, NOT TWICE, BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, K"}
18:29:10,477 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,478 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,480 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "PTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMITTEE AND EVERY MEMBER ON THIS -- IN THIS HOUSE SHOULD BE PROUD TO COME TO THE FLOOR AND VOTE TO SUPPORT THEIR FRIENDS, THEIR NEIGHBORS, THEIR CONSTITUENTS IN THESE VERY, VERY DARK TIMES. I YIELD BACK THE BALANCE OF MY TIME. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI IS\nRECOGNIZED. THANK YOU, MR. SPEAKER. MR. SPEAKER, I WOULD ONCE AGAIN JUST COMMEND THE GREAT WORK AND ADVOCACY THAT MR. STEUBE, MR. LA MALFA, MR. THOMPSON -- I CAN TELL YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT"}
18:29:10,482 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,485 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,489 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "MR. SPEAKER, I WOULD ONCE AGAIN JUST COMMEND THE GREAT WORK AND ADVOCACY THAT MR. STEUBE, MR. LA MALFA, MR. THOMPSON -- I CAN TELL YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT, I URGE ALL MEMBERS TO SUPP REMARKS ARE ABOUT HALF AN HOUR. ... YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT, I URGE ALL MEMBERS TO SUPP REMARKS ARE ABOUT HALF AN HOUR."}
18:29:10,498 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
18:29:10,499 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
18:29:10,501 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK, C ALIFORNIA AND OVER A DOZEN O THER STATES HAVE BE EN DEVASTA TED BY DISA STE RS. THERE'S NOT A SINGL E COLLEAG UE IN THIS HO USE WHO SHOULD HAVE TO GO THROUGH A DISASTE R TO KNOW HO W BAD IT IS. THI S DE VASTA TES COMMUNITIES, IT DEVASTA TES PEOPLE'S LIVES, IT DISRUPT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMIT"}
18:29:10,505 datashaper.workflow.workflow INFO executing verb merge_graphs
18:29:10,525 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
18:29:10,995 graphrag.index.run INFO Running workflow: create_final_covariates...
18:29:10,996 graphrag.index.run INFO dependencies for create_final_covariates: ['create_base_text_units']
18:29:10,998 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
18:29:11,11 datashaper.workflow.workflow INFO executing verb extract_covariates
18:29:11,17 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
18:29:11,60 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o: TPM=0, RPM=0
18:29:11,62 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o: 25
18:29:11,414 datashaper.workflow.workflow INFO executing verb window
18:29:11,418 datashaper.workflow.workflow INFO executing verb genid
18:29:11,420 datashaper.workflow.workflow INFO executing verb convert
18:29:11,422 datashaper.workflow.workflow INFO executing verb rename
18:29:11,425 datashaper.workflow.workflow INFO executing verb select
18:29:11,437 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_covariates.parquet
18:29:11,559 graphrag.index.run INFO Running workflow: create_summarized_entities...
18:29:11,561 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
18:29:11,566 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
18:29:11,575 datashaper.workflow.workflow INFO executing verb summarize_descriptions
18:29:11,586 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
18:29:11,684 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
18:29:11,685 graphrag.index.run INFO dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']
18:29:11,692 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
18:29:11,710 datashaper.workflow.workflow INFO executing verb select
18:29:11,716 datashaper.workflow.workflow INFO executing verb aggregate_override
18:29:11,736 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_covariate_ids.parquet
18:29:11,866 graphrag.index.run INFO Running workflow: create_base_entity_graph...
18:29:11,874 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
18:29:11,877 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
18:29:11,884 datashaper.workflow.workflow INFO executing verb cluster_graph
18:29:11,886 graphrag.index.verbs.graph.clustering.cluster_graph WARNING Graph has no nodes
18:29:11,892 datashaper.workflow.workflow ERROR Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/indexers/utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
18:29:11,896 graphrag.index.reporting.file_workflow_callbacks INFO Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key details=None
18:29:11,898 graphrag.index.run ERROR error running workflow create_base_entity_graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/run.py", line 323, in run_pipeline
    result = await workflow.run(context, callbacks)
  File "/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
  File "/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/indexers/utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
18:29:11,899 graphrag.index.reporting.file_workflow_callbacks INFO Error running pipeline! details=None
