04:51:18,720 graphrag.config.read_dotenv INFO No .env file found at app
04:51:18,729 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 56",
        "type": "openai_chat",
        "model": "gpt-4o",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "app",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 5,
        "strategy": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
04:51:18,736 graphrag.index.create_pipeline_config INFO skipping workflows 
04:51:18,750 graphrag.index.run INFO Running pipeline
04:51:18,750 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at app/output/20240801-045118/artifacts
04:51:18,755 graphrag.index.input.load_input INFO loading input from root_dir=input
04:51:18,755 graphrag.index.input.load_input INFO using file storage for input
04:51:18,756 graphrag.index.storage.file_pipeline_storage INFO search app/input for files matching .*\.txt$
04:51:18,758 graphrag.index.input.text INFO found text files from input, found [('full_transcript.txt', {})]
04:51:18,765 graphrag.index.input.text INFO Found 1 files, loading 1
04:51:18,771 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
04:51:18,772 graphrag.index.run INFO Final # of rows loaded: 1
04:51:18,885 graphrag.index.run INFO Running workflow: create_base_text_units...
04:51:18,886 graphrag.index.run INFO dependencies for create_base_text_units: []
04:51:18,886 datashaper.workflow.workflow INFO executing verb orderby
04:51:18,890 datashaper.workflow.workflow INFO executing verb zip
04:51:18,891 datashaper.workflow.workflow INFO executing verb aggregate_override
04:51:18,898 datashaper.workflow.workflow INFO executing verb chunk
04:51:20,373 datashaper.workflow.workflow INFO executing verb select
04:51:20,383 datashaper.workflow.workflow INFO executing verb unroll
04:51:20,390 datashaper.workflow.workflow INFO executing verb rename
04:51:20,391 datashaper.workflow.workflow INFO executing verb genid
04:51:20,393 datashaper.workflow.workflow INFO executing verb unzip
04:51:20,394 datashaper.workflow.workflow INFO executing verb copy
04:51:20,395 datashaper.workflow.workflow INFO executing verb filter
04:51:20,404 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
04:51:20,557 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
04:51:20,558 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
04:51:20,560 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
04:51:20,597 datashaper.workflow.workflow INFO executing verb entity_extract
04:51:20,603 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
04:51:20,621 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
04:51:20,622 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
04:51:20,679 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,679 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,682 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THST:\nTHE : WITHOUT\nOBJECTION\nTHE GENTLEMAN IS RECOGNIZED THANK YOU, MR. SPEAKER, I RISE IN SUPPORT OF H.R. 5863, THE FEDERAL DISASTER TAX RELIEF ACT. INTRODUCED BY MY WAYS AND MEANS COLLEAGUE FROM BEL STEUBE. THIS LEGISLATION WAS APPROVED LAST YEAR BY THE WAYS AND MEANS COMMITTEE 38-0 BECAUSE FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER"}
04:51:20,684 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,684 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,686 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "UE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT TO BE A BIPARTISAN VICTORY, THEY HAVE BEEN SITTING ON THE TAX BILL FOR FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNIT"}
04:51:20,688 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,689 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,694 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST OF GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nCALIFORN'}
04:51:20,695 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,698 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,700 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nCALIFORNIA IS RECOGNIZED. I YIELD MYSELF\nSUCH TIME AS I MAY CONSUME. JARNGD. I RISE IN STRONG SUPPORT OF THIS LEGISLATION AND I THANK CHAIRMAN SMITH OF THE WAYS AND MEANS COMMITTEE FOR ALL OF THE GOOD WORK HE HAS DONE TO ENSURE WE ARE ABLE TO HELP OUR CONSTITUENTS WHO ARE SUFFERING AS A RESULT OF NATURAL DISASTERS AND COLLEAGUE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTIT"}
04:51:20,701 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,702 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,705 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'ORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST OF GETTING THIS DONE, HE BROADEND HIS RELIEF EFFORT TO INCLUDE OVER 300 STORMS IN 45 STATES. I ENCOURAGE ALL OF MY COLLEAGUES TO VOTE YES ON THIS BILL SO WE ARE STANDING WITH AND SUPPORTING OUR FELLOW NEIGHBORS WHEN THEY ARE MOST IN NEED. I RESERVE. ... LEGISLATION WAS APPROVED LAST YEAR BY THE WAYS AND MEANS COMMITTEE 38-0 BECAUSE FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMM'}
04:51:20,709 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,710 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,713 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "FAMILIES AND COMMUNITIES ACROSS THE COUNTRY WHO SUFFERED DISASTERS NEED SUPPORT. IN FACT, BIPARTISAN SUPPORT FOR THIS LEGISLATION WAS SO STRONG THAT IT WAS APPROVED A SECOND TIME BY THE WAYS AND MEANS COMMITTEE AS PART OF THE TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT. THIS LEGISLATION NOT ONLY HELPS VICTIMS OF DISASTERS BUT PROVIDES BROAD AND IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER TAX RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLOR"}
04:51:20,718 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,718 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,721 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT'S WHY WE HAVE BEEN SO SUCCESSFUL IN PASSING THIS LEGISLATION NUMEROUS TIMES OUT OF THE WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TO"}
04:51:20,722 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,722 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,725 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS"}
04:51:20,727 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,727 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,730 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE FIRES. AS PART OF ITS SUBSEQUENT BANKRUPTCY PROCEEDINGS, THE UTILITY ESTABLISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SA'}
04:51:20,730 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,731 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,733 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IMMEDIATE TAX RELIEF FOR AMERICAN WORKERS, FARMERS, FAMILIES AND SMALL BUSINESSES, WHICH IS WHY THE HOUSE OF REPRESENTATIVES PASSED IT WITH 84% SUPPORT EARLIER THIS YEAR. I ENCOURAGE MY SENATE COLLEAGUES TO TAKE UP THAT LEGISLATION TO SUPPORT DISASTER VICTIMS AND HELP THE MILLIONS OF AMERICANS TREADING WATER IN TODAY'S ECONOMY. THE FEDERAL DISASTER TAX RELIEF ACT PROVIDES ASSISTANCE TO COMMUNITIES ACROSS THE COUNTRY BRINGING RELIEF TO THOSE RECOVERING AND REBUILDING AFTER TRAGIC FLOODS AND TORNADOES LIKE THOSE AFFECTED COMMUNITIES IN MY HOME STATE OF MISSOURI IN THE WINTER OF 2021 AND SUMMER OF 2023. HURRICANES LIKE HURRICANE IAN THAT CLAIMED COUNTLESS LIVES IN FLORIDA, WILDFIRES THAT DEVASTATED COMMUNITIES IN CALIFORNIA AND HAWAII AND THE TRAIN DERAILMENT AND TOXIC IN EAST PALESTINE, OHIO. I WANT TO COMMEND REPRESENTATIVE STEUBE FOR HIS LEADERSHIP. HIS PASSION STARTED WITH HIS DESIRE TO PROVIDE HELP TO THE FAMILIES HE REPRESENTS WHO WERE DEVASTATED BY THE HURRICANE. BUT IN THE INTEREST"}
04:51:20,773 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,773 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,775 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR. STEUBE, ONE OF OUR COL LEAGUES ON THE COM MITTEE. I W ISH SUCH AN UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. ... WE ARE ABLE TO HELP"}
04:51:20,776 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,777 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,778 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "OMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT"}
04:51:20,782 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,782 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,784 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO VICTIMS OF NATURAL DISASTERS. SINCE 2021, 3 1-R DISASTERS HAVE BEEN DECLARED WITHOUT CONGRESS TAKING ACTION. WILDFIRES ACROSS THE WESTERN UNITED STATES AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A'}
04:51:20,785 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,786 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,788 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. ... WE ARE ABLE TO HELP OUR CONSTITUENTS WHO ARE SUFFERING AS A RESULT OF NATURAL DISASTERS AND COLLEAGUE AND FRIEND, MR. STEUBE WHO WITHOUT HIS LEADERSHIP ON THE WAYS AND MEANS COMMITTEE, WE WOULDN'T BE HERE TODAY. AND ALSO, MR. LAMALFA, MY COLLEAGUE TO THE NORTH OF MY DISTRICT 2HO 2AS WORKED WITH ME OVER THE YEARS TO ADDRESS ONE COMPONENT THAT IS COVERED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT"}
04:51:20,793 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,793 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,795 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE FIRES. AS PART OF ITS SUBSEQUENT BANKRUPTCY PROCEEDINGS, THE UTILITY ESTABLISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND"}
04:51:20,796 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,797 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,798 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'ED BY THIS PIECE OF LEGISLATION. THIS HAS BEEN A LONG TIME COMING FOR MY CONSTITUENTS, TOO LONG, WAY TOO LONG. NOW THE SECOND TIME IN FIVE MONTHS THAT THIS HOUSE HAS COME TOGETHER TO STATE PLAINLY AND IN BIPARTISAN FASHION THAT AMERICANS SHOULD HELP ONE ANOTHER WHEN DISASTER STRIKES. WHILE THE SENATE CONTINUES TO PLAY POLITICS WIT H WHAT OUG HT TO BE A BIPARTISAN VICTORY, THEY HAVE BEEN SITTING ON THE TAX BILL FOR FIVE MONTHS. AND I JOIN CHAIRMAN SMITH IN CALLING FOR THEM TO MOVE THE ENTIRE BIL L, BEC AUSE THERE IS SO MUCH IN THAT FOR SO MANY OF OUR CONSTITUENTS ACROSS THE COUNTRY. AND I JUST WANT TO BRIEFLY REITERATE HOW WE GOT HERE TODAY. IN MY DISTRICT, WILDFIRES IN 2015, 2017 AND 2018 DEVASTATED ENTIRE COMMUNITIES ACROSS MY DISTRICT AND ACROSS THE STATE OF CALIFORNIA. ENTIRE TOWNS WERE DESTROYED. THOUSANDS OF PEOPLE LOST HOMES. DOZENS OF PEOPLE LOST THEIR LIVES. IN THE AFTERMATH, THE COURTS FOUND THAT PACIFIC GAS AND ELECTRIC WAS LIABLE FOR CAUSING SOME OF THESE'}
04:51:20,799 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,800 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,801 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR. STEUBE, ONE OF OUR COL LEAGUES ON THE COM MITTEE. I W ISH SUCH AN UNUSUAL STR ATEGY TO GET HER E WASN'T NEC ESSARY. I AM COM MITTED AND I THINK MY COLLEAGUES ARE COMMITTED TO PUL LING EVERY LEVER TO GET THIS BIL L PASSED. THI S 2S A FUNDAMENTAL QUESTION OF FAIRNESS AND I URGE ALL MY COLLEAGUES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nMISSOURI IS RECOGNIZED. I WANT TO THANK CONGRESSMAN THOMPSON FOR HIS ADVOCACY ON HIS LEGISLATION AND MOVING IT THROUGH THE COMMITTEE IN A VERY BIPARTISAN EFFORT. I YIELD SUCH TIME AS HE MAY CONSUME"}
04:51:20,805 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,805 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,807 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'UES TO VOTE IN FAVOR OF THIS BILL. AND I RESERVE. THE\nGENTLEMAN RESERVES THE BALANCE\nOF HIS TIME. THE GENTLEMAN FROM\nMISSOURI IS RECOGNIZED. I WANT TO THANK CONGRESSMAN THOMPSON FOR HIS ADVOCACY ON HIS LEGISLATION AND MOVING IT THROUGH THE COMMITTEE IN A VERY BIPARTISAN EFFORT. I YIELD SUCH TIME AS HE MAY CONSUME TO THE AUTHOR OF THIS LEGISLATION, THE GENTLEMAN FROM FLORIDA, MR. STEUBE. ... TIME AS HE MAY CONSUME TO THE AUTHOR OF THIS LEGISLATION, THE GENTLEMAN FROM FLORIDA, MR. STEUBE. THE\nGENTLEMAN IS RECOGNIZEDST I STAND IN SUPPORT OF H.R. 5863. AND HISTORIC ACT LAST WEEK THE MAJORITY OF THE HOUSE OF REPRESENTATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE K'}
04:51:20,808 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,809 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,810 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT'S WHY WE HAVE BEEN SO SUCCESSFUL IN PASSING THIS LEGISLATION NUMEROUS TIMES OUT OF THE WAYS AND MEANS COMMITTEE AND OFF THE FLOOR OF THIS HOU SE. THIS BILL HAS BEEN STA LLED, ADV ANCED AND THEN HEL D UP. IT HAS BEEN MAR KED UP AND PAS SED THE HOUSE AND STALLED AGA IN. THE SEN ATE OUGHT TO STOP DIG ITTERRING ON WHAT IS A GOO D BILL FOR THIS COU NTRY AND JUS T PASS IT. WE ARE HER E AGA IN TONIGHT TORE TAK E THIS MATTER UP. I'M GRATEFUL TO MY COLLEAGUES ON BOTH SIDES OF THE AIS LE. MR. NEAL, OUR RANKING MEM BER ON WAYS AND MEANS, HAS BEE N A GRE AT COL LEAGUE AND CHAMPION. THE CHA IRMAN, MR. SMI TH, AND MR"}
04:51:20,813 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,814 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,815 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'ATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO V'}
04:51:20,835 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,837 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,839 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A VARIETY OF DISASTERS, INCLUDING TORNADOES, FLOODING AND FIRES. THIS DOESN'T JUST IMPACT CALIFORNIA, IT CONGRESS MUST ACT TO PROVIDE THEM RELIEF. I'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA,"}
04:51:20,840 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,840 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,842 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA, AS WELL AS CONGRESSWOMAN JOE WILSON TOKUDA OF HAWAII FOR THEIR LEADERSHIP ON THIS EFFORT. I'D LIKE TO THANK CONGRESSMAN BILL JOHNSON WHO PLAYED AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. ... RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON"}
04:51:20,843 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,843 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,845 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "S FIRSTHAND THE TRAGEDY OF WILDFIRES, HER CONSTITUENTS EX PERIENCED A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. ... A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. THE\nGENTLELADY FROM HAWAII IS\nRECOGNIZED FOR TO MINUTES. THANK YOU, MR. SPEAKER. I RISE IN STRONG SUPPORT OF H.R. 586 3-RBGS THE FEDERAL DISASTER TAX RELIEF ACT OF 2023. IT WILL KEEP SURVIVORS' HARD-EARNED MONEY IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL"}
04:51:20,846 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,846 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,848 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'IDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO VICTIMS OF NATURAL DISASTERS. SINCE 2021, 3 1-R DISASTERS HAVE BEEN DECLARED WITHOUT CONGRESS TAKING ACTION. WILDFIRES ACROSS THE WESTERN UNITED STATES AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN'}
04:51:20,855 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,855 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,857 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. THE\nGENTLEMAN FROM FLORIDA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. SPEAKER, I'D LIKE TO YIELD TWO MINUTES TO THE GENTLELADY 2ROM 2AWAII, MS. TOKUDA, WHO KNOWS FIRSTHAND THE TRAGEDY OF WILDFIRES, HER CONSTITUENTS EX PERIENCED A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN HER HOME STATE. AND SHE HAS BEEN THERE WITH THEM EVERY STEP OF THE WAY AND SHE'S HERE ON THEIR BEHALF AGAIN TONIGHT. THANK YOU FOR YO UR SUPPORT AND I YIELD. ... A HORRIFIC, HORRIFIC DIS ASTER IN HER DISTRICT, IN"}
04:51:20,858 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,858 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,861 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND STAFF WHO HAVE WORKED TIRELESSLY ON THIS BILL. I WOULD LIKE TO GIVE A SPECIAL THANKS TO CALIFORNIA CONGRESSMAN MIKE THOMPSON, JIMMY PANETTA, DOUG LAMALFA, AS WELL AS CONGRESSWOMAN JOE WILSON TOKUDA OF HAWAII FOR THEIR LEADERSHIP ON THIS EFFORT. I'D LIKE TO THANK CONGRESSMAN BILL JOHNSON WHO PLAYED AN IMPORTANT ROLE WITH THIS BILL AND A SPECIAL THANKS TO WAYS AND MEANS COMMITTEE CHAIRMAN JASON SMITH FOR PASSING THIS BILL OUT OF THE COMMITTEE. THE CONSTITUENTS IN MY DISTRICT AND THE DISTRICTS EACH OF YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS"}
04:51:20,862 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,863 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,865 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "E AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING WE CAN DO TO LIGHTEN THE TAX BURDENS AND THE FINANCIAL STRUGGLES THEY FACE WILL IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN."}
04:51:20,867 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,867 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,870 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'YOU REPRESENT ARE IN NEED OF HELP. AND TODAY I URGE SWIFT PASSAGE OF THIS BILL ON THE HOUSE FLOOR AND URGE EXPEDITIOUS CONSIDERATION IN THE SENATE SO THAT AMERICANS ALL ACROSS AMERICA CAN GET MUCH-NEEDED RELIEF. I YIELD BACK. ... RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP'}
04:51:20,871 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,872 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,874 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IEF ACT OF 2023. IT WILL KEEP SURVIVORS' HARD-EARNED MONEY IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD EVER BUDGET FOR. ACROSS OUR COUNTRY, THROUGH ALL DISASTERS, CURRENT, THOSE TO COME AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION"}
04:51:20,875 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,875 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,877 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "AND MAUI IMPACTED AMERICANS WHO HAVE NOT RECEIVED RELIEF. THE SIMILARLY, VICTIMS OF THE EAST PALESTINE TRAIN DERAILMENT ARE FACING SIMILAR ISSUES. THIS BILL HELPS AMERICANS AND ALLOWS THEM TO DEDUCT AID FOR NATURAL DISASTERS FROM THEIR TAXES. IT WILL PROVIDE RELIEF FOR MILLIONS WHO HAVE BEEN AFFECTED BY NATURAL DISASTERS, IN THE NORTHEAST, VICTIMS OF WILDFIRES WILL BE -- WILL GET THE RELIEF THEY DESERVE. THOSE WHO FACE WINTER STORMS WILL GET PROTECTION. OUR FRIEND IN TEXAS WHO HAVE EXPERIENCED A VARIETY OF DISASTERS, INCLUDING TORNADOES, FLOODING AND FIRES. THIS DOESN'T JUST IMPACT CALIFORNIA, IT CONGRESS MUST ACT TO PROVIDE THEM RELIEF. I'M GRATEFUL TO BE SUPPORTED BY MANY OF COMIE COLLEAGUES ON BOTH SIDES OF THE AISLE TO LEAD THE FIGHT FOR AMERICANS ALL ACROSS THE COUNTRY, TO GET DISASTER RELIEF. DISASTER RELIEF IS NO T A DEMOCRAT PROBLEM OR A REPUBLICAN PROBLEM, IT'S SOMETHING THAT ALL OF US FACE. I WOULD LIKE TO GIVE A SINCERE THANKS TO MEMBERS AND"}
04:51:20,909 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,909 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,910 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. ... IN THEIR POCKETS AND HELP THEM IN GETTING THEIR LIVES BACK TO NORMAL AS SOON AS POSSIBLE. WHATEVER THAT NORMAL MIGHT LOOK LIKE. SEEING THE OVERWHELMING CHALLENGES FACED BY THE SURVIVORS OF THE MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD"}
04:51:20,912 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,912 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,913 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "IMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. THE\nGENTLELADY YIELDS BACK.\nTHE GENTLEMAN FROM CALIFORNIA\nRESERVES.\nAND THE GENTLEMAN FROM MISSOURI\nIS RECOGNIZED. YOU, MR. SPEAKER.\nI YIELD SUCH TIME AS HE MAY\nCONSUME TO THE GENTLEMAN FROM\nCALIFORNIA, MR. LAMALFA. THE\nGENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. THANK YOU, MR. SPEAKER. AND THANK YOU SO MUCH, CHAIRMAN SMITH, FOR HELPING US WITH OUR LEGISLATION ALL THIS TIME HERE AND I'M VERY GRATEFUL ALSO TO MR. STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIP"}
04:51:20,914 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,915 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,917 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME BECAUSE OF A BAD INTERPRETATION HERE? THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES"}
04:51:20,917 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,918 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,919 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING WE CAN DO TO LIGHTEN THE TAX BURDENS AND THE FINANCIAL STRUGGLES THEY FACE WILL IT A LONG WAY TO REBUILD LIVES AND REBUILDING COMMUNITIES. I AM PROUD TO JOIN CONGRESSMAN STEUBE, LAMALFA AND THOMPSON ON THE FLOOR TODAY TO PASS THIS BILL OUT OF THE HOUSE, AN D I IMPLORE THE SENATE TO EMBRACE AND PASS THIS BILL. DISASTER DOES NOT DISCRIMINATE. IT DOESN'T CARE IF YOU'RE DEMOCRAT, INDEPENDENT OR REPUBLICAN. BUT WHEN IT HITS, PEOPLE NEED HELP. WE MUST PASS THIS CRITICAL BIPARTISAN PIECE OF LEGISLATION NOW. THANK YOU, MR. SPEAKER. AND I YIELD BACK. THE\nGENTLELADY YIELDS BACK.\nTHE GENTLEMAN FROM CALIFORNIA\nRESERVES.\nAND THE GENTLE"}
04:51:20,920 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,920 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,922 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING, DID THEIR NEIGHBOR GET OUT? DID THE ELDERLY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE ST"}
04:51:20,922 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,923 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,923 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS, WE WANT TO GET R ESULTS. IT'S BEEN A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE"}
04:51:20,930 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,930 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,931 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "MAUI WILDFIRES, I INTRODUCED H.R. 5873, THE NATURAL DISASTER TAX RELIEF ACT OF 2023, LAST OCTOBER, TO LESSEN THE TAX BURDEN FACED BY DISASTER SURVIVORS AND ENSURE THEY HAVE THE FINANCIAL RESOURCES TO SUPPORT THEIR OHANA. SINCE THEN, FAR TOO MANY PEOPLE CONTINUE TO STRUGGLE WITH RECOVERY COSTS THAT NO ONE COULD EVER BUDGET FOR. ACROSS OUR COUNTRY, THROUGH ALL DISASTERS, CURRENT, THOSE TO COME AND SO FAR IN THE PAST, THEY'VE REACHED DEEP INTO THEIR SAVES, THEY'VE GONE INTO DEBT TO FEED THEIR KIDS, TO COVER THEIR MORTGAGES, TO PAY FOR EDUCATION AND HEALTH CARE COSTS AND REBUILD THEIR HOMES, BUSINESSES AND LIVELIHOODS. I WANT TO THANK MY FRIENDS AND COLLEAGUES FOR INCORPORATING ELEMENTS OF MY LEGISLATION INTO THIS BILL, AS WE CONTINUE TO FIGHT FOR ITS CRITICAL PASSAGE. LIKE ME, THEY KNOW ALL TOO WELL THAT THERE WILL NEVER BE ENOUGH TO REPLACE ALL THAT PEOPLE LOST. AS THE GOOD CONGRESSMAN FROM CALIFORNIA MENTIONED, NO ONE WILL BE MADE WHOLE, BUT THAT BEING SAID, ANYTHING, ANYTHING"}
04:51:20,932 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,932 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,933 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THIS TIME HERE AND I'M VERY GRATEFUL ALSO TO MR. STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , WIT H THE LOSSES WE'VE SUFFERED, ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE"}
04:51:20,934 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,935 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,936 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "LY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR MORTGAGE, MAYBE IT'S ALREADY PAID OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW"}
04:51:20,936 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,937 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,938 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RESOUNDINGLY. I HOPE SO. I ASK FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY P"}
04:51:20,953 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,953 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,955 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , WIT H THE LOSSES WE'VE SUFFERED, ALO NG WITH OUR CONSTITUE NT, OUR CONSTITUENT, OF COURSE, ESPECIALLY, I T'S VERY PAI NFUL TO SE E AND TO NOT BE ABL E TO GO BACK TO THEM AND SAY, WE'VE GOTTEN THE RE SULT YE T. BUT MY OWN CO NSTITUENT S, I COMMEND THEM, I'M GRATEFUL FOR THEM, THE Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS,"}
04:51:20,956 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,956 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,958 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR MORTGAGE, MAYBE IT'S ALREADY PAID OFF. YOU'VE GOT YUREK WHICH THE IN YOUR HOME -- YOUR EQUITY IN YOUR HOME. SO THIS DISASTER HAPPENS. YOU LOSE YOUR HOME. ALL OF A SUDDEN YOU'VE GOT TO REARRANGE YOUR LIFE, YOU HAVE TO REBUILD YOUR LIFE. THAT PORTION OF THAT EQUITY THAT NOW IS GOING TO BE COMPENSATED FOR PARTLY BY THE SETTLEMENT WITH THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME"}
04:51:20,959 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,959 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,960 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. ... STEUBE FOR ALLOWING OUR BILL TO BE PIGGYBACKED WITH HIS IN THIS EFFORT HERE AS WELL AS THE 7024 TAX RELIEF FOR AMERICAN FAMILIES AND WORKERS ACT, WHICH IS STILL WAITING OVER IN THE SENATE. I HOPE WE CAN GET THAT ONE, BUT I'M VERY GRATEFUL FOR EVERYBODY TO JOIN THIS EFFORT HERE TODAY. A STRONG BIPARTISAN EFFORT TO MOVE THIS NARROWER, MUCH MORE -- VERY IMPORTANT DISASTER RELIEF PACKAGE TO HELP PEOPLE ALL ACROSS THE COUNTRY, AS HAS BEEN SAID. MY COLLEAGUE, MIKE THOMPSON, THANK YOU SO MUCH FOR OUR PARTNERSHIP ON THIS. IT'S TAKEN SOME TIME AND WE'RE GETTING THERE. GLAD TO SEE. YOU KNOW , W"}
04:51:20,965 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,966 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,968 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "LATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. MR. SPEAKER, I\nHAVE NO FURTHER SPEAKERS AND I'M\nPREPARED TO CLOSE. WE'RE PREPARED TO\nCLOSE. THE\nGENTLEMAN IS RECOGNIZED. THANK YOU, MR. SPEAKER. AGAIN, I'D LIKE TO THANK MR. STEUBE, MR. LAMALFA, CHAIRMAN SMITH AND ALL OF OUR COLLEAGUES ON WAYS AND MEANS WHO WORKED SO HARD TO BRING THIS BILL TO FRUI TIO N NOT ONCE, NOT TWICE, BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, K"}
04:51:20,968 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,970 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,971 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "WAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING, DID THEIR NEIGHBOR GET OUT? DID THE ELDERLY LAID UPTHE STREET -- LADY UP THE STREET GET OUT? MAYBE THERE WAS A FIREFIGHTER OR NEIGHBOR WHO HELPED THAT LADY GET OUT JUST IN TIME SO THERE WASN'T WORSE LOSS OF LIFE. THE RESILIENCE OF THESE FOLKS IN THE FIRES THAT I'VE HAD IN MY DISTRICT, NEIGHBORS AND OTHER NEIGHBORING STATES, IS JUST AMAZING. AS THEY'VE STUCK WITH US ON THIS. SO AS SETTLEMENT HAPPENED WITH THE UTILITY, SOMEHOW PARTLY COMPENSATE AND WON'T EVER BE MADE WHOLE, THEY CAN NEVER BE MADE WHOLE, EVEN WITH A LOT OF MONEY, THAT SETTLEMENT SHOULD NOT BE TAXABLE -- A TAXABLE EVENT. BREAK THAT DOWN FOR A MINUTE. YOU'RE IN YOUR HOME, YOU'VE BEEN PAYING OFF YOUR M"}
04:51:20,973 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,973 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,976 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Y'VE BEEN VERY, VERY PA TIENT, THE VICTIMS OF TH E CAMP FIRE WHE RE 85 LIVES WERE LO ST. MY NEIG HBORS IN SANTA ROSA AREA, AND OF COURSE MY GOOD FRIEND, MS. T OKUDA IN LAHAINA, WHO SUFFERED EVEN MORE GREATLY LOSS OF LIFE THAN WHAT OUR S HAD BEEN, A RECORD IN P ARADISE. WE DON'T WANT TO SET RECORDS, WE WANT TO GET R ESULTS. IT'S BEEN A G REAT PARTNERSHIP ON TOP OF DISAST ER AND HEART ACH E. SO JUST PICTU RE THIS, THOUGH. AS I TALK ABO UT PARADISE. YOU WAKE UP IN 2HE 2ORNING, YOU HEAR THERE'S FIRE. ALL OF A SUDDEN THERE'S AN EVACUATION. PEOPLE ARE CROWDING THE NARROW ROADWAYS TRYING TO GET UP THE HILL OR DOWN THE HILL, OUT OF TOWN. BARELY MAKING IT IN SOME CASES. SCORCHED VEHICLES. TIRES ON FIRE. ALL THAT. THEY'RE SEEING IN THEIR REAR-VIEW MIRROR THEIR NEIGHBORHOODS ENGULFED IN FLAMES, THEIR HOUSES GOING DOWN, ALL THEIR MOW ALL THEIR M MOMENTOS ARE IN THE. THEY'RE WONDERING,"}
04:51:20,977 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,978 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,979 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK, C ALIFORNIA AND OVER A DOZEN O THER STATES HAVE BE EN DEVASTA TED BY DISA STE RS. THERE'S NOT A SINGL E COLLEAG UE IN THIS HO USE WHO SHOULD HAVE TO GO THROUGH A DISASTE R TO KNOW HO W BAD IT IS. THI S DE VASTA TES COMMUNITIES, IT DEVASTA TES PEOPLE'S LIVES, IT DISRUPT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMEND"}
04:51:20,981 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,982 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,983 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "THE UTILITY, THAT PORTION OF YOUR HOME IS NOW A NEWLY TAXABLE EVENT. BECAUSE OF THE I.R.S. INTERPRETATION ON THAT. HOW IS THAT RIGHT? HOW IS THAT FAIR AT ALL THAT YOU HAVE RIPPED OUT OF YOUR LIFE YOUR HOME, YOUR FAMILY, WHATEVER MAY HAVE HAPPENED TO YOU PERSONALLY, AND NO W YOU HAVE A TAXABLE EVENT ON TOP OF THAT PIECE OF EQUITY THAT WAS IN YOUR HOME BECAUSE OF A BAD INTERPRETATION HERE? THAT'S WHY THIS LEGISLATION IS NECESSARY. THAT'S WHY IT'S BEEN SO STRONGLY SUPPORTED ON BOTH SIDES OF THE AISLE, ALL THROUGH THE PROCESS HERE. THAT'S WHY WE NEED TO EVERCOME THESE HURD -- OVERCOME THESE HURDLES WE HAVE TO GET THIS DONE. PEOPLE DESERVE TO HAVE THAT PREDICTABILITY, THAT SUSTAINABILITY OF THEIR LIFE, TO BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RES"}
04:51:20,985 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,986 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,992 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "PT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMITTEE AND EVERY MEMBER ON THIS -- IN THIS HOUSE SHOULD BE PROUD TO COME TO THE FLOOR AND VOTE TO SUPPORT THEIR FRIENDS, THEIR NEIGHBORS, THEIR CONSTITUENTS IN THESE VERY, VERY DARK TIMES. I YIELD BACK THE BALANCE OF MY TIME. ... TO BRING THIS BILL TO FRUI TIO N NOT ONCE, NOT TWICE, BUT NOW THREE T IMES. AND OUR FRIEND FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK"}
04:51:20,993 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:20,995 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:20,999 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "BE ABLE TO PUT IT BACK AND PUT THEMSELVES BACK INTO A GOOD WAY AGAIN. SO, FIRE VICTIMS, CAMP FIRE IN MY AREA, ZOG FIRE, OUR OTHER NEIGHBORS THERE, RELIEF IS ON THE WAY HERE. THIS HAS BEEN A TREMENDOUS EFFORT. A LIT TLE OUT OF THE ORD INARY TO GET THIS LEGISLATION BACK TO THIS FLOOR HERE TONIGHT. AND I THINK IT WILL PASS RESOUNDINGLY. I HOPE SO. I ASK FOR EVERYBODY'S AYE VOTE. AGAIN, I APPRECIATE ALL MY COLLEAGUES, BOTH SIDES OF THE AISLE, FOR STEPPING FARD AND DOING RIGHT BY THE FIRE VICTIMS, BY THE HURRICANE VICTIMS, BY THE FOLKS IN EAST PALESTINE AND OTHERS WHO ARE GOING TO BE ADDED INTO THIS. THIS IS HOW LEGISLATION SHOULD LOOK. THIS IS HOW THE COUNTRY PULLS TOGETHER. I'M GLAD TO BE A PART OF IT. I YIELD BACK. THANK YOU. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI\nRESERVES.\nTHE GENTLEMAN FROM CALIFORNIA IS\nRECOGNIZED. MR. SPEAKER, I\nHAVE NO FURTHER SPEAKERS AND"}
04:51:21,6 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:21,6 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:21,8 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "FROM HAWA II, I KNOW HO W DIF FICULT THAT IS IN YOUR STATE IN YOUR AREA , WHAT A DEVASTA TING FIRE THAT WAS AND I KNOW HO W HARD YOU'RE WORKING FOR YOUR CO NSTITUENTS AND THANK Y OU FOR BEING ON THE FLOOR T ODAY. MR. SPEAKER , FLORIDA, TEXAS, SOUTH CAROLIN A, LOUISIA NA, KENTUCKY, OREGON, NEW YORK, C ALIFORNIA AND OVER A DOZEN O THER STATES HAVE BE EN DEVASTA TED BY DISA STE RS. THERE'S NOT A SINGL E COLLEAG UE IN THIS HO USE WHO SHOULD HAVE TO GO THROUGH A DISASTE R TO KNOW HO W BAD IT IS. THI S DE VASTA TES COMMUNITIES, IT DEVASTA TES PEOPLE'S LIVES, IT DISRUPT S COMMUNITIES, IT DISR UPTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMIT"}
04:51:21,11 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:21,11 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:21,17 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "PTS PEOPLE'S 2IVES. PEOPLE ARE KILLED, BUSINESSES ARE LOST, HOMES AND HEIRLOOMS ARE LOST AND DESTROYED. THE LEAST THAT WE CAN DO IS TO COME TO THE AID OF OUR CONSTITUENTS, OUR FELLOW AMERICANS, IN TIMES OF DISASTER AND IN TIMES OF GREAT NEED AND THAT'S WHAT WE'RE DOING TODAY. THIS IS COMMENDABLE WORK BY THE WAYS AND MEANS COMMITTEE AND EVERY MEMBER ON THIS -- IN THIS HOUSE SHOULD BE PROUD TO COME TO THE FLOOR AND VOTE TO SUPPORT THEIR FRIENDS, THEIR NEIGHBORS, THEIR CONSTITUENTS IN THESE VERY, VERY DARK TIMES. I YIELD BACK THE BALANCE OF MY TIME. THE\nGENTLEMAN FROM CALIFORNIA YIELDS\nBACK.\nTHE GENTLEMAN FROM MISSOURI IS\nRECOGNIZED. THANK YOU, MR. SPEAKER. MR. SPEAKER, I WOULD ONCE AGAIN JUST COMMEND THE GREAT WORK AND ADVOCACY THAT MR. STEUBE, MR. LA MALFA, MR. THOMPSON -- I CAN TELL YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT"}
04:51:21,20 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': 'It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\n'}
04:51:21,21 root ERROR error extracting graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 123, in __call__
    result = await self._process_document(text, prompt_variables)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 173, in _process_document
    continuation = await self._llm(
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py", line 36, in _execute_llm
    embedding = await self.client.embeddings.create(
TypeError: AsyncEmbeddings.create() got an unexpected keyword argument 'logit_bias'
04:51:21,22 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "MR. SPEAKER, I WOULD ONCE AGAIN JUST COMMEND THE GREAT WORK AND ADVOCACY THAT MR. STEUBE, MR. LA MALFA, MR. THOMPSON -- I CAN TELL YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT, I URGE ALL MEMBERS TO SUPP REMARKS ARE ABOUT HALF AN HOUR. ... YOU, THEY'VE BEEN ADVOCATING SINCE I'VE BEEN CHAIRMAN THAT THIS IS AN IMPORTANT PIECE OF LEGISLATION TO GET ACROSS THE FINISH LINE AND LET'S HOPE THAT THE UNITED STATES SENATE DOES THE SAME THING. WITH THAT, I URGE ALL MEMBERS TO SUPP REMARKS ARE ABOUT HALF AN HOUR."}
04:51:21,23 datashaper.workflow.workflow INFO executing verb merge_graphs
04:51:21,32 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
04:51:21,129 graphrag.index.run INFO Running workflow: create_final_covariates...
04:51:21,130 graphrag.index.run INFO dependencies for create_final_covariates: ['create_base_text_units']
04:51:21,131 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
04:51:21,139 datashaper.workflow.workflow INFO executing verb extract_covariates
04:51:21,144 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
04:51:21,160 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o: TPM=0, RPM=0
04:51:21,161 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o: 25
04:51:21,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
04:51:21,565 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': "\n-Target activity-\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\n\n-Goal-\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\n\n-Steps-\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\nFor each claim, extract the following information:\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\n\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\n\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n-Examples-\nExample 1:\nEntity specification: organization\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n<|COMPLETE|>\n\nExample 2:\nEntity specification: Company A, Person C\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n##\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\n<|COMPLETE|>\n\n-Real Data-\nUse the following input for your answer.\nEntity specification: ['organization', 'person', 'geo', 'event']\nClaim description: Any claims or facts that could be relevant to information discovery.\nText: ATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO V\nOutput:"}
04:51:21,566 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
04:51:21,568 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
04:51:21,570 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': "\n-Target activity-\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\n\n-Goal-\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\n\n-Steps-\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\nFor each claim, extract the following information:\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\n\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\n\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n-Examples-\nExample 1:\nEntity specification: organization\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n<|COMPLETE|>\n\nExample 2:\nEntity specification: Company A, Person C\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n##\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\n<|COMPLETE|>\n\n-Real Data-\nUse the following input for your answer.\nEntity specification: ['organization', 'person', 'geo', 'event']\nClaim description: Any claims or facts that could be relevant to information discovery.\nText: ISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS\nOutput:"}
04:51:21,572 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
04:51:21,588 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
04:51:21,591 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': "\n-Target activity-\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\n\n-Goal-\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\n\n-Steps-\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\nFor each claim, extract the following information:\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\n\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\n\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n-Examples-\nExample 1:\nEntity specification: organization\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n<|COMPLETE|>\n\nExample 2:\nEntity specification: Company A, Person C\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n##\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\n<|COMPLETE|>\n\n-Real Data-\nUse the following input for your answer.\nEntity specification: ['organization', 'person', 'geo', 'event']\nClaim description: Any claims or facts that could be relevant to information discovery.\nText: OMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT\nOutput:"}
04:51:21,592 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
04:51:22,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
04:51:22,769 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': "\n-Target activity-\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\n\n-Goal-\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\n\n-Steps-\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\nFor each claim, extract the following information:\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\n\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\n\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n-Examples-\nExample 1:\nEntity specification: organization\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n<|COMPLETE|>\n\nExample 2:\nEntity specification: Company A, Person C\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n##\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\n<|COMPLETE|>\n\n-Real Data-\nUse the following input for your answer.\nEntity specification: ['organization', 'person', 'geo', 'event']\nClaim description: Any claims or facts that could be relevant to information discovery.\nText: OMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS ARE TOLD THEY MAY OWE TAXES ON THESE PAYMENTS BECAUSE DEPENDING ON THE TAXPAYER, THE PAYMENTS MAY QUALIFY AS INCOME. IN FOUR YEARS OF WORKING ON THIS ISSUE, I HA VE YET TO EN COUNTER A SINGLE PER SON ON EIT HER SIDE OF THE AISLE WHO BELIEVES THIS IS FAIR. THAT\nOutput:"}
04:51:22,771 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
04:51:22,774 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
04:51:22,780 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': "\n-Target activity-\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\n\n-Goal-\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\n\n-Steps-\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\nFor each claim, extract the following information:\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\n\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\n\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n-Examples-\nExample 1:\nEntity specification: organization\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n<|COMPLETE|>\n\nExample 2:\nEntity specification: Company A, Person C\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n##\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\n<|COMPLETE|>\n\n-Real Data-\nUse the following input for your answer.\nEntity specification: ['organization', 'person', 'geo', 'event']\nClaim description: Any claims or facts that could be relevant to information discovery.\nText: ISHED A TRUST FROM FIRE SURVIVORS ARE GENERALLY ELIGIBLE FOR COMPENSATION FOR LOSSES SUSTAINED DURING THESE FIRES. LET ME PAUSE HERE TO SAY ONE THING. NO DISASTER SURVIVOR IS EVER MADE WHOLE. NO ONE IS EVER MADE WHOLE. PEOPLE LOST THEIR HOMES AND EVERYTHING IN THEIR HOMES. FAMILY PICTURES, FAMILY RECORDS. THEY LOST BU SINESSES AND AS I SAID EARLIER, SADLY THEY LOST FAMILY MEMBERS. AND WHILE THE COURTS EVENTUALLY CREATED A PATH TO COMPENSATION, IT TOOK YEARS TO GET THERE, YEARS MY CONSTITUENTS DIDN'T HAVE. THEY COULDN'T WAIT AROUND FOR THREE, FO UR, SIX YEARS TO GE T A PAYMENT FROM THAT TRUST AND THEN BECAUSE THE TRUST WAS STRUCTURED IN THE FORM OF STOCK SHARES AND BECAUSE STOCK SHA RES NEED TO BEMON ADVERTISED CAREFULLY AND SLOWLY IN ORDER TO MAXIMIZE RETURNS TO SURVIVORS, THE PAYMENTS TO SURVIVORS CAME IN BATCHES. NOBODY IS GETTING, REPEAT, NOBODY IS GETTING 100% OF WHAT THEY LOST. AND THEN TO ADD INSULT TO INJURY, RIDERS OUR CONSTITUENTS STARTED TO GET EVEN A LITTLE BIT OF COMPENSATION, OUR CONSTITUENTS\nOutput:"}
04:51:22,785 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
04:51:23,407 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
04:51:23,418 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': "\n-Target activity-\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\n\n-Goal-\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\n\n-Steps-\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\nFor each claim, extract the following information:\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\n\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\n\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n-Examples-\nExample 1:\nEntity specification: organization\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n<|COMPLETE|>\n\nExample 2:\nEntity specification: Company A, Person C\nClaim description: red flags associated with an entity\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\nOutput:\n\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\n##\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\n<|COMPLETE|>\n\n-Real Data-\nUse the following input for your answer.\nEntity specification: ['organization', 'person', 'geo', 'event']\nClaim description: Any claims or facts that could be relevant to information discovery.\nText: ATIVES MADE CLEAR THAT THE HOUSE SHOULD ACT TO PROVIDE TAX RELIEF TO VICTIMS OF NATURAL DISASTERS ALL ACROSS AMERICA. I THANK EVERY MEMBER WHO STOOD WITH ME ON THIS FIGHT. ON SEPTEMBER 28, 2022, SOUTHWEST FLORIDA WAS RAVAGED BY HURRICANE IAN ONE OF THE MOST DEVASTATING. NO ONE RANKS HIM AS THE THIRD COSTLIEST HURRICANE KILLING 150 PEOPLE AND CAUSING BILLIONS OF DOLLARS IN DAMAGES. FOR FLORIDIANS, THE RECOVERY IS FAR FROM OVER. DESPITE EXPERIENCING HURRICANES, FLORIDIANS ARE RESILIENT. I HAVE BEEN WORKING ON LEGISLATION TO RECOVER FROM STORMS THAT HAVE DECIMATED MANY STORMS. -- COMMUNITIES. THE SUN COAST IS STILL WAITING FOR CONGRESS TO DO ITS JOB AND PROVIDE RELIEF. MORE THAN A YEAR AFTER LAND FALL, CONGRESS HAS TO PROVIDE DISASTER RELIEF. I RECEIVED THOUSANDS OF LETTERS, CALLS AND PLEAS FOR HELP WHO INCURRED THOUSANDS OF DOLLARS IN RECOVERY EXPENSES AN D HAVING A HARD TIME GETTING AHEAD. ON EIGHT SEPARATE KEYINGS SINCE 2022, CONGRESS HAS PROVIDED TAX RELIEF TO V\nOutput:"}
04:51:23,421 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
04:51:24,917 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:24,933 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.753999999957159. input_tokens=1415, output_tokens=230
04:51:25,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:25,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.3109999999869615. input_tokens=1415, output_tokens=273
04:51:25,571 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:25,576 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.314999999944121. input_tokens=1414, output_tokens=296
04:51:26,978 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:26,991 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.819000000017695. input_tokens=1414, output_tokens=384
04:51:28,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:28,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.483000000007451. input_tokens=1415, output_tokens=452
04:51:30,171 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:30,180 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 4.480000000097789. input_tokens=1416, output_tokens=386
04:51:30,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:30,974 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 5.849000000045635. input_tokens=1414, output_tokens=478
04:51:33,412 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
04:51:33,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 7.241000000038184. input_tokens=1414, output_tokens=388
04:51:33,447 datashaper.workflow.workflow INFO executing verb window
04:51:33,452 datashaper.workflow.workflow INFO executing verb genid
04:51:33,453 datashaper.workflow.workflow INFO executing verb convert
04:51:33,456 datashaper.workflow.workflow INFO executing verb rename
04:51:33,457 datashaper.workflow.workflow INFO executing verb select
04:51:33,462 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_covariates.parquet
04:51:33,635 graphrag.index.run INFO Running workflow: create_summarized_entities...
04:51:33,635 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
04:51:33,637 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
04:51:33,641 datashaper.workflow.workflow INFO executing verb summarize_descriptions
04:51:33,647 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
04:51:33,734 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
04:51:33,735 graphrag.index.run INFO dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']
04:51:33,736 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
04:51:33,745 datashaper.workflow.workflow INFO executing verb select
04:51:33,746 datashaper.workflow.workflow INFO executing verb aggregate_override
04:51:33,752 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_covariate_ids.parquet
04:51:33,848 graphrag.index.run INFO Running workflow: create_base_entity_graph...
04:51:33,849 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
04:51:33,850 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
04:51:33,855 datashaper.workflow.workflow INFO executing verb cluster_graph
04:51:33,855 graphrag.index.verbs.graph.clustering.cluster_graph WARNING Graph has no nodes
04:51:33,857 datashaper.workflow.workflow ERROR Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/indexers/utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
04:51:33,866 graphrag.index.reporting.file_workflow_callbacks INFO Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key details=None
04:51:33,867 graphrag.index.run ERROR error running workflow create_base_entity_graph
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/run.py", line 323, in run_pipeline
    result = await workflow.run(context, callbacks)
  File "/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
  File "/usr/local/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "/usr/local/lib/python3.10/site-packages/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/usr/local/lib/python3.10/site-packages/pandas/core/indexers/utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
04:51:33,869 graphrag.index.reporting.file_workflow_callbacks INFO Error running pipeline! details=None
